Hypertext transfer protocol

client -> HTML (request) 

server -> response

http -> request와 response를 나타냄
컨텐츠를 주고 받기 위해서는 
client와 server가 서로 알아들을 수 있는
양식이 필요하고 이것이 http이다

인터넷 검사 (개발자 도구)

=> network -> request headers는 
본인의 웹브라우저가 웹서버에게 요청한 데이터임

사용자가 요청한 정보를 웹서버에 대신 요청해주는..
=> request headers

웹서버는 자신이 가지고 있는 정보를 보내주면서

응답 헤더를 만들어주는 기계


get -> 데이터를 웹서버로부터 받아오는 방식

login 하여 데이터를 주는 것 -> post

host는 인터넷에 연결된 컴퓨터를 식별하는 것
요청하는 웹사이트의 웹서버의 주소를 적는 것

user-agent -> 요청하는 웹브라우져가 어떤 웹브라우져인지..
운영체제가 무엇인지도 파악 가능
=> 웹서버 운영시 우리 사이트는 누가 무슨 체제를 많이 쓰는지
확인가능함

검색엔진 로봇도 접근할 수 있는데, 그럴 때는 웹서버는
요청을 차단할 수 있음

accept-encoding : 응답하는 데이터양이 많으면 압축을 받은 상태로 전달받고
이후 압축을 품

이 웹브라우져는 어떤 압축방식을 지원하는지

if-modified-since : 마지막으로 언제 다운받았는지 웹서버에게 알려줌
=> 응답할 때 가지고 있는 파일 중 뭐가 최신인지 파악해서
속도를 빠르게 할 수 있음


response message

100번대
200번대 : 성공했다. 디테일한 사족을 다는 것
300번대 : redirection => 웹브라우져가 다시 다른 곳으로 이동함
400번대 : client errors => 

ex) 404 not founds => 어떤 주소로 접속했는데 서버에 없음
    403 forbidden => 접속하면 안되는 곳에 접속함 (관계자 외 출입금지)

500번대 : 서버쪽에 문제
     ex) 500 internal server error : 서버 자체 문제가
        
content-length : byte로 받아오는 content의 용량

https , ssl 을 이용한 것과 http의 차이점
s는 secure임

현재 web을 통해 사생활 정보를 다루므로,
https는 전송하고 있는 내용을 가로채도 뭐가 있는지 당사자만 암
(암호화 됨)
그러므로 http에서 정보를 받는다면, 꼭 안된다!

cache => 한 번 웹사이트에 와서 데이터를 저장하면
또 다시 다운로드하는게 아니라 이미 저장된 파일을 읽어서
성능을 향상시킨다

cache는 내용이 갱신되었을 때도 브라우져는 그 사실을 모름
웹 브라우져에서 윈도우는 crtl+f5를 누르면 강제로 갱신함
하지만 캐시가 갱신된지 아닌지 사용자는 알 수 없다

=> 이를 위해 cache-control , pragma => cache를 제어하는 tool

-개인화

쇼핑몰에서 장바구니, 한번 접속하면.. 로그인 상태를 유지하는 것
이러한 기록들을 웹사이트와 웹브라우져가 기록하기 때문임
=> cookie 
쿠기값을 설정하면 웹사이트에서 전송해서 사용자의 상태를 식별하고 기억함

=> 더나아가 web storage라는 기술이 등장, proxy(웹브라우저 -웹서버 사이에서 중계 서버를 둠) (보안공격 막고 요청 분산..)

네트워킹 모니터링 도구 (네트워크 모니터링 툴(developer tools))
wireshark=> 컴퓨터에서 일어나는 모든 network traffic을 읽을 수 있다

